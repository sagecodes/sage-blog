---
layout: post
title:  "My 100 days of ML code - Round 1"
permalink: /100daysofmlcode/
date:   2019-07-18
categories: post
tags: machine-learning
author: Sage Elliott
published: true
---

A diary type post of my 100 days of Machine learning code [#100DaysofMLcode](https://twitter.com/search?q=%23100DaysOfMLCode&src=tyah).

## Day 1 â˜‘

Continue learning about classification models in scikit learn.

I did a couple of k-NN implementations as I Continue working through common classification models in sklearn. I had done an iris k-NN before but using an external dataset let me use Label Encoders!

#### Code for the day:

- [Iris Classification](https://github.com/sagecodes/irsit-classification2-knn)
- [T-Shirt Classfication](https://github.com/sagecodes/tshirt-size-prediction-KNN)



## Day 2 â˜‘

Went to a [Python Meetup](https://www.meetup.com/PSPPython/) discussing time series forecasting at scale with FB Prophet so I thought I would do an implementation using it. Used it on a Chicago crime dataset. 

Read more about forecasting at scale with prophet [here]( https://peerj.com/preprints/3190.pdf).

Read more about Time series [here](https://otexts.com/fpp2/arima.html). 

 Find the github for Facebook prohet [here](https://github.com/facebook/prophet). 

#### Code for the day:

- [Chicago Crime Rate forecast](https://github.com/sagecodes/chicago-crime-prediction-fbprophet)
 

## Day 3 â˜‘

Another prophet forecasting implementation on one of the most important commodities ğŸ¥‘ Avocados! The price looks like its dropping over all across the US but rises  across west coast regions. I'll never be able to buy a house #millennial

Refreshed on some SQL and updating content on a SQL workshop

#### Code for the day:

- [Avocado Price forecast](https://github.com/sagecodes/avocado-forecasting-fbprophet)
- [Intro to SQL workshop for my workshop](https://github.com/sagecodes/intro-to-sql)


## Day 4 â˜‘

Learned more about using decision trees and random forests also about text feature extraction with sklearn CountVectorizer.
Used this to predict is a customer reviews on alexa were positive or negative.

Dataset used: [Kaggle Amazon Alexa Reviews](https://www.kaggle.com/sid321axn/amazon-alexa-reviews)

#### Code for the day:

- [Alexa Amazon Review Classfication](https://github.com/sagecodes/Amazon-Review-Classification-Random-Forest)




## Day 5 â˜‘

More Random Forests

More Decision Trees and Random Forests. I'm really impressed with the random forest results! Used this Kyphosis Kaggle datset and visually it seems very hard to classify data points, but the classifier worked well. Cool to see how much better the random forest performed vs just the decsion tree.

Dataset used: [Kaggle Kyphosis](https://www.kaggle.com/abbasit/kyphosis-dataset)

#### Code for the day:

[Kyphosis Prediction Random Forest](https://github.com/sagecodes/kyphsis-classifier-random-forest/blob/master/kyphosis-prediction-random-forest.ipynb)


## Day 6 â˜‘

Built Naive Bayes classifier on Email dataset to detect spam / not spam. 

Also used Naive Bayes classifier a credit card dataset to detect fraud.

Completed [ Machine Learning Classification Bootcamp in Python](https://www.udemy.com/certificate/UC-MWZST68M/)




#### Code for the day:

- [Email Spam Classifer with Naive Bayes](https://github.com/sagecodes/spam-classifier-naive-bayes/blob/master/Spam%20classifier.ipynb)
- [Credit Card Fraud with Naive Bayes](https://github.com/sagecodes/credit-fraud-classfier-naive-bayes/blob/master/Credit%20Card%20Fraud%20Classifier.ipynb)


## Day 7 â˜‘

1 week down! ğŸ‰

Today was a good refresher on performing linear regrssion with scikit learn.

I Performed 2 simple linear regression case studies. Temperature vs. ice cream revenue (relevant today in Seattle) & Horsepower vs fuel consumption.

#### Code for the day:

- [Icecream vs. Temp](https://github.com/sagecodes/Icecream-temp-simple-linear-regression/blob/master/ice%20cream%20vs%20temp%20regression.ipynb)
- [Fuel Consumption vs. horsepower](https://github.com/sagecodes/fuel-consumption-linear-regression/blob/master/fuel%20consumption.ipynb)

## Day 8 â˜

Regression performance

Polynomial regrssion

Multiple Linear regrssion

Logistic regrssion

Artificial Neural Networks & Regression

Lasso & ridge regression

## Day 9 â˜

Artificial Neural Network prediction



## Day 10 â˜

Deep Neural Networks CIFAR



## Day 11 â˜

Deep Learning & LE-NET


## Day 12 â˜

NLP w/ Bayes 

## Day 13 â˜

Reccomender System


## Day 14 â˜

Deep Learning For Computer Vision

## Day 15 â˜


## Day 16 â˜

## Day 17 â˜

## Day 18 â˜

## Day 19 â˜

## Day 20 â˜

## Day 21 â˜

## Day 22 â˜

## Day 23 â˜

## Day 24 â˜

## Day 25 â˜

## Day 26 â˜

## Day 27 â˜

## Day 28 â˜

## Day 29 â˜

## Day 30 â˜

## Day 31 â˜

## Day 32 â˜

## Day 33 â˜

## Day 34 â˜

## Day 35 â˜

## Day 36 â˜

## Day 37 â˜

## Day 38 â˜

## Day 39 â˜

## Day 40 â˜

## Day 41 â˜

## Day 42 â˜

## Day 41 â˜

## Day 42 â˜

## Day 43 â˜

## Day 44 â˜

## Day 45 â˜

## Day 46â˜

## Day 47 â˜

## Day 48 â˜

## Day 49 â˜

## Day 50 â˜
HALF WAY!

## Day 51 â˜

## Day 52 â˜

## Day 53 â˜

## Day 54 â˜

## Day 55 â˜

## Day 56 â˜

## Day 57 â˜

## Day 58 â˜

## Day 59 â˜

## Day 60 â˜

## Day 61 â˜

## Day 62 â˜

## Day 63 â˜

## Day 64 â˜

## Day 65 â˜

## Day 66 â˜

## Day 67 â˜

## Day 68 â˜

## Day 69 â˜

## Day 70 â˜

## Day 71 â˜

## Day 72 â˜

## Day 73 â˜

## Day 74 â˜

## Day 75 â˜

## Day 76 â˜

## Day 77 â˜

## Day 78 â˜

## Day 79 â˜

## Day 80 â˜

## Day 81 â˜

## Day 82 â˜

## Day 83 â˜

## Day 84 â˜

## Day 85 â˜

## Day 86 â˜

## Day 87 â˜

## Day 88 â˜

## Day 89 â˜

## Day 90 â˜

## Day 91 â˜

## Day 92 â˜

## Day 93 â˜

## Day 94 â˜

## Day 95 â˜

## Day 96 â˜

## Day 97 â˜

## Day 98 â˜

## Day 99 â˜

## Day 100 â˜
DONE!!